{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f10f52-932a-486a-93f4-c26e52040729",
   "metadata": {},
   "source": [
    "# What is Gensim?\n",
    "Gensim is an open-source Python library for <b>unsupervised topic modeling</b> and <b>natural language processing</b>, using modern statistical machine learning.\n",
    "\n",
    "# What is Word2Vec?\n",
    "Word2Vec is a model that transforms words into vectors of numbers (word embeddings), capturing their semantic meaning. It uses neural networks to learn relationships between words based on their usage in a large corpus.\n",
    "\n",
    "There are two main archituctures:\n",
    "1. <b>CBOW (Continuous Bag of Words)</b> – Predicts a word from surrounding context words.\\\n",
    "2. <b>Skip-Gram</b> – Predicts surrounding context words given a word.\n",
    "\n",
    "## Why Gensim for Word2Vec?\n",
    "* It's optimized and fast\n",
    "* Easy to train and save/load models\n",
    "* Preprocessing and tokenization support\n",
    "* Scalable to large corpor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695e56d-dcf9-4340-867a-ec17c664f5a2",
   "metadata": {},
   "source": [
    "# How to Use Word2Vec with Gensim\n",
    "1. Install Gensim\n",
    "   * pip install gensim\n",
    "  \n",
    "2. Prepare the Data\n",
    "\n",
    "   \n",
    "    You need a list of tokenized sentences:\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1db379-2258-4a2a-a4a5-834e10247c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    ['i', 'love', 'machine', 'learning'],\n",
    "    ['deep', 'learning', 'is', 'fun'],\n",
    "    ['i', 'love', 'natural', 'language', 'processing']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2916f4-43b9-4e87-a77b-216e0e272d27",
   "metadata": {},
   "source": [
    "3. Train the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fc4146-15ff-4e26-938e-0a6d02a6c7c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m Word2Vec(sentences, vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a9476-eb06-43dd-bc25-428f983297d2",
   "metadata": {},
   "source": [
    "## Parameters:\n",
    "\n",
    "* vector_size: Dimensionality of the word vectors\n",
    "\n",
    "* window: Maximum distance between the current and predicted word\n",
    "\n",
    "* min_count: Ignores words with total frequency lower than this\n",
    "\n",
    "* workers: Number of CPU threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a14e67-c018-465c-b0df-8bb700f61203",
   "metadata": {},
   "source": [
    "4. Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fe17a-a74e-4684-94c3-d578afd4eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"word2vec.model\")\n",
    "\n",
    "# Load model\n",
    "model = Word2Vec.load(\"word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78a02b-bf5a-4def-8109-cbc8d95e561c",
   "metadata": {},
   "source": [
    "5. Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491f6c6-611c-4268-8905-56742a24f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Word Vector\n",
    "vector = model.wv['machine']\n",
    "\n",
    "# Similar Words\n",
    "model.wv.most_similar('learning', topn=5)\n",
    "\n",
    "# Word Similarity\n",
    "model.wv.similarity('machine', 'learning')\n",
    "\n",
    "# Analogy\n",
    "model.wv.most_similar(positive=['king', 'woman'], negative=['man'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5d299-d743-4870-bae4-6423db0530c8",
   "metadata": {},
   "source": [
    "# Tokenization Tip\n",
    "#### You should preprocess your text before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa871ad0-3ea0-46b4-bc8b-c371dd5f74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "text = \"I love data science and machine learning!\"\n",
    "tokens = simple_preprocess(text)\n",
    "# ['love', 'data', 'science', 'and', 'machine', 'learning']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e648fc0-6690-4202-bb64-25c58eb5c78c",
   "metadata": {},
   "source": [
    "## Visualizing Word Embeddings\n",
    "Use *TSNE* from *sklearn.manifold* to reduce dimensions and plot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a587dfb-c927-4f6f-98d7-7104b45b51a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
